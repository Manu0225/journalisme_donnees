alpha = 0.75
),
pch = 7
)
},
)
}
generation = rgen(n = 20)
x = generation$x
res = EM(x, 2)
display_problem(res,generation,x)
knitr::opts_chunk$set(echo = TRUE)
library(emdbook)
library(MASS)
library(MCMCpack)
rgen = function(n) {
p1 = rbeta(n = 1,
shape1 = 0.5,
shape2 = 0.5)
Sigma = riwish(2, diag(2))
Xi = rcauchy(n = 1,
location = 0,
scale = 10)
mu1 = mvrnorm(n = 1,
mu = c(Xi, Xi),
Sigma = Sigma)
mu2 = mvrnorm(n = 1,
mu = c(Xi, Xi),
Sigma = Sigma)
mu_diff = replicate(n, mu2 - mu1)
translate_matrix =
sample(c(0, 1),
size = n,
replace = T,
prob = c(p1, 1 - p1)) *
t(mu_diff)
return (list(
x = translate_matrix + mvrnorm(n = n, mu = mu1, Sigma = Sigma),
mu1 = mu1,
mu2 = mu2,
Sigma = Sigma,
p1=p1
))
}
tr.dat = function(generation, noise, sys_biais, censor) {
##
# noise = std of the gaussian noise
# sys biais = number to add to the data
# censor = proportion of the data to forget
n = length(generation$x[,1])
generation$x=generation$x + sys_biais + noise * rnorm(n=2*n)
generation$x=generation$x[-c(sample(1:n, size = as.integer(n*censor))), ]
return(generation)
}
log_mvdnorm = function(x, mu, Sigma) {
k = length(mu)
xp = x - mu
return (((-1 / 2 * t(xp) %*% solve(Sigma) %*% xp) - 1 / 2 * log ((2 * pi) ** k *
det(Sigma)))[1])
}
responsabilites = function(x, mu1, mu2, Sigma, prop) {
K = 2
N = dim(x)[1]
log_gamma = matrix(nrow = N, ncol = K)
for (i in 1:N) {
log_gamma[i, 1] = log(prop[1]) + log_mvdnorm(x[i, ], mu1, Sigma)
log_gamma[i, 2] = log(prop[2]) + log_mvdnorm(x[i, ], mu2, Sigma)
}
gamma = exp(log_gamma)
gamma = sweep(gamma, 1, rowSums(gamma), FUN = "/")
return(gamma)
}
params = function(x, gamma) {
K = 2
N = dim(x)[1]
G1 = colSums(gamma) # vecteur de longueur K=2
G2 = t(gamma) %*% x # matrice K×K = 2×2
M1 = matrix(0, nrow = 2, ncol = 2)
M2 = matrix(0, nrow = 2, ncol = 2)
for (i in 1:N) {
tmp = x[i, ] %*% t(x[i, ])
M1 = M1 + gamma[i, 1] * tmp
M2 = M2 + gamma[i, 2] * tmp
}
mu = G2 / G1
Sigma1 = (M1 - (G2[1, ]) %*% t(G2[1, ]) / G1[1]) / G1[1]
Sigma2 = (M2 - (G2[2, ]) %*% t(G2[2, ]) / G1[2]) / G1[2]
Sigma = (G1[1] * Sigma1 + G1[2] * Sigma2) / N
prop = G1 / N
return(list(
mus = mu,
Sigma = Sigma,
props = prop
))
}
EM = function(x, K, nb_iters = 50) {
# initial values = something not too far from the data
mu1 = colMeans(x)
mu2 = mu1 + runif(K)
Sigma = diag(c(1, 1))
prop = runif(K)
prop = prop / sum(prop)
mu11_vector = rep(0, nb_iters)
mu12_vector = rep(0, nb_iters)
mu21_vector = rep(0, nb_iters)
mu22_vector = rep(0, nb_iters)
for (i in 1:nb_iters) {
gamma = responsabilites(x, mu1, mu2, Sigma, prop)
new_params = params(x, gamma)
mus = new_params[[1]]
mu1 = mus[1, ]
mu2 = mus[2, ]
Sigma = new_params[[2]]
prop = new_params[[3]]
mu11_vector[i] = mu1[1]
mu12_vector[i] = mu1[2]
mu21_vector[i] = mu2[1]
mu22_vector[i] = mu2[2]
}
return(list(mu1 = mu1,
mu2 = mu2,
Sigma = Sigma,
prop=prop,
mu11_vector = mu11_vector,
mu12_vector = mu12_vector,
mu21_vector = mu21_vector,
mu22_vector = mu22_vector))
}
display_problem = function (res, generation, x) {
list_estimated_mu11 = res$mu11_vector
list_estimated_mu12 = res$mu12_vector
list_estimated_mu21 = res$mu21_vector
list_estimated_mu22 = res$mu22_vector
N = length(list_estimated_mu11)
X_real = generation$x
mu1_estimated = res$mu1
mu2_estimated = res$mu2
Sigma_estimated = res$Sigma
mu1_real = generation$mu1
mu2_real = generation$mu2
Sigma_real = generation$Sigma
tg = function(x, y) {
sum(
generation$p1 * dmvnorm(c(x, y), mu1_real, Sigma_real) +
(1 - generation$p1) * dmvnorm(c(x, y),  mu2_real, Sigma_real)
)
}
tg = Vectorize(tg)
x_min = min(min(list_estimated_mu11), min(list_estimated_mu21)) - 10
x_max = max(max(list_estimated_mu11), max(list_estimated_mu21)) + 10
y_min = min(min(list_estimated_mu12), min(list_estimated_mu22)) - 10
y_max = max(max(list_estimated_mu12), max(list_estimated_mu22)) + 10
xx <- seq(from = x_min, to = x_max, by = 0.5)
yy <- seq(from = y_min, to = y_max, by = 0.5)
zz <- outer(X = xx, Y = yy, tg)
filled.contour(
x = xx,
y = yy,
z = zz,
nlevels = 100,
color.palette = topo.colors,
#plot.axes=contour(xx, yy, zz, nlevels=20, add=TRUE),
plot.axes = {
axis(1, seq(x_min, x_max, length.out = 10))
axis(2, seq(y_min, y_max, length.out = 10))
points(x = list_estimated_mu11, y = list_estimated_mu12, col =
"red")
points(
x = list_estimated_mu21,
y = list_estimated_mu22,
col = "purple",
pch = 3
)
points(
generation$mu1[1],
generation$mu1[2] ,
col = rgb(
red = 0,
green = 0,
blue = 0,
alpha = 0.75
),
pch = 7
)
points(
generation$mu2[1],
generation$mu2[2] ,
col = rgb(
red = 0,
green = 0,
blue = 0,
alpha = 0.75
),
pch = 7
)
},
)
}
generation = rgen(n = 20)
x = generation$x
res = EM(x, 2)
display_problem(res,generation,x)
generation = rgen(n = 500)
x = generation$x
res = EM(x, 2)
display_problem(res,generation,x)
generation = rgen(n = 20)
x = generation$x
res = EM(x, 2)
display_problem(res,generation,x)
new_generation1 = tr.dat(generation, noise = 2, sys_biais = 1, censor = 0.5)
new_x1 = new_generation1$x
new_res1 = EM(new_x1, 2)
display_problem(new_res1,generation,new_x1)
new_generation2 = tr.dat(generation, noise = 10, sys_biais = 1, censor = 0.5)
new_x2 = new_generation2$x
new_res2 = EM(new_x2, 2)
display_problem(new_res2,generation,new_x2)
knitr::opts_chunk$set(echo = TRUE)
library(emdbook)
library(MASS)
library(MCMCpack)
rgen = function(n) {
p1 = rbeta(n = 1,
shape1 = 0.5,
shape2 = 0.5)
Sigma = riwish(2, diag(2))
Xi = rcauchy(n = 1,
location = 0,
scale = 10)
mu1 = mvrnorm(n = 1,
mu = c(Xi, Xi),
Sigma = Sigma)
mu2 = mvrnorm(n = 1,
mu = c(Xi, Xi),
Sigma = Sigma)
mu_diff = replicate(n, mu2 - mu1)
translate_matrix =
sample(c(0, 1),
size = n,
replace = T,
prob = c(p1, 1 - p1)) *
t(mu_diff)
return (list(
x = translate_matrix + mvrnorm(n = n, mu = mu1, Sigma = Sigma),
mu1 = mu1,
mu2 = mu2,
Sigma = Sigma,
p1=p1
))
}
tr.dat = function(generation, noise, sys_biais, censor) {
##
# noise = std of the gaussian noise
# sys biais = number to add to the data
# censor = proportion of the data to forget
n = length(generation$x[,1])
generation$x=generation$x + sys_biais + noise * rnorm(n=2*n)
generation$x=generation$x[-c(sample(1:n, size = as.integer(n*censor))), ]
return(generation)
}
log_mvdnorm = function(x, mu, Sigma) {
k = length(mu)
xp = x - mu
return (((-1 / 2 * t(xp) %*% solve(Sigma) %*% xp) - 1 / 2 * log ((2 * pi) ** k *
det(Sigma)))[1])
}
responsabilites = function(x, mu1, mu2, Sigma, prop) {
K = 2
N = dim(x)[1]
log_gamma = matrix(nrow = N, ncol = K)
for (i in 1:N) {
log_gamma[i, 1] = log(prop[1]) + log_mvdnorm(x[i, ], mu1, Sigma)
log_gamma[i, 2] = log(prop[2]) + log_mvdnorm(x[i, ], mu2, Sigma)
}
gamma = exp(log_gamma)
gamma = sweep(gamma, 1, rowSums(gamma), FUN = "/")
return(gamma)
}
params = function(x, gamma) {
K = 2
N = dim(x)[1]
G1 = colSums(gamma) # vecteur de longueur K=2
G2 = t(gamma) %*% x # matrice K×K = 2×2
M1 = matrix(0, nrow = 2, ncol = 2)
M2 = matrix(0, nrow = 2, ncol = 2)
for (i in 1:N) {
tmp = x[i, ] %*% t(x[i, ])
M1 = M1 + gamma[i, 1] * tmp
M2 = M2 + gamma[i, 2] * tmp
}
mu = G2 / G1
Sigma1 = (M1 - (G2[1, ]) %*% t(G2[1, ]) / G1[1]) / G1[1]
Sigma2 = (M2 - (G2[2, ]) %*% t(G2[2, ]) / G1[2]) / G1[2]
Sigma = (G1[1] * Sigma1 + G1[2] * Sigma2) / N
prop = G1 / N
return(list(
mus = mu,
Sigma = Sigma,
props = prop
))
}
EM = function(x, K, nb_iters = 50) {
# initial values = something not too far from the data
mu1 = colMeans(x)
mu2 = mu1 + runif(K)
Sigma = diag(c(1, 1))
prop = runif(K)
prop = prop / sum(prop)
mu11_vector = rep(0, nb_iters)
mu12_vector = rep(0, nb_iters)
mu21_vector = rep(0, nb_iters)
mu22_vector = rep(0, nb_iters)
for (i in 1:nb_iters) {
gamma = responsabilites(x, mu1, mu2, Sigma, prop)
new_params = params(x, gamma)
mus = new_params[[1]]
mu1 = mus[1, ]
mu2 = mus[2, ]
Sigma = new_params[[2]]
prop = new_params[[3]]
mu11_vector[i] = mu1[1]
mu12_vector[i] = mu1[2]
mu21_vector[i] = mu2[1]
mu22_vector[i] = mu2[2]
}
return(list(mu1 = mu1,
mu2 = mu2,
Sigma = Sigma,
prop=prop,
mu11_vector = mu11_vector,
mu12_vector = mu12_vector,
mu21_vector = mu21_vector,
mu22_vector = mu22_vector))
}
display_problem = function (res, generation, x) {
list_estimated_mu11 = res$mu11_vector
list_estimated_mu12 = res$mu12_vector
list_estimated_mu21 = res$mu21_vector
list_estimated_mu22 = res$mu22_vector
N = length(list_estimated_mu11)
X_real = generation$x
mu1_estimated = res$mu1
mu2_estimated = res$mu2
Sigma_estimated = res$Sigma
mu1_real = generation$mu1
mu2_real = generation$mu2
Sigma_real = generation$Sigma
tg = function(x, y) {
sum(
generation$p1 * dmvnorm(c(x, y), mu1_real, Sigma_real) +
(1 - generation$p1) * dmvnorm(c(x, y),  mu2_real, Sigma_real)
)
}
tg = Vectorize(tg)
x_min = min(min(list_estimated_mu11), min(list_estimated_mu21)) - 10
x_max = max(max(list_estimated_mu11), max(list_estimated_mu21)) + 10
y_min = min(min(list_estimated_mu12), min(list_estimated_mu22)) - 10
y_max = max(max(list_estimated_mu12), max(list_estimated_mu22)) + 10
xx <- seq(from = x_min, to = x_max, by = 0.5)
yy <- seq(from = y_min, to = y_max, by = 0.5)
zz <- outer(X = xx, Y = yy, tg)
filled.contour(
x = xx,
y = yy,
z = zz,
nlevels = 100,
color.palette = topo.colors,
#plot.axes=contour(xx, yy, zz, nlevels=20, add=TRUE),
plot.axes = {
axis(1, seq(x_min, x_max, length.out = 10))
axis(2, seq(y_min, y_max, length.out = 10))
points(x = list_estimated_mu11, y = list_estimated_mu12, col =
"red")
points(
x = list_estimated_mu21,
y = list_estimated_mu22,
col = "purple",
pch = 3
)
points(
generation$mu1[1],
generation$mu1[2] ,
col = rgb(
red = 0,
green = 0,
blue = 0,
alpha = 0.75
),
pch = 7
)
points(
generation$mu2[1],
generation$mu2[2] ,
col = rgb(
red = 0,
green = 0,
blue = 0,
alpha = 0.75
),
pch = 7
)
},
)
}
generation = rgen(n = 20)
x = generation$x
res = EM(x, 2)
display_problem(res,generation,x)
generation = rgen(n = 500)
x = generation$x
res = EM(x, 2)
display_problem(res,generation,x)
generation = rgen(n = 20)
x = generation$x
res = EM(x, 2)
display_problem(res,generation,x)
new_generation1 = tr.dat(generation, noise = 2, sys_biais = 1, censor = 0.5)
new_x1 = new_generation1$x
new_res1 = EM(new_x1, 2)
display_problem(new_res1,generation,new_x1)
new_generation2 = tr.dat(generation, noise = 10, sys_biais = 1, censor = 0.5)
new_x2 = new_generation2$x
new_res2 = EM(new_x2, 2)
display_problem(new_res2,generation,new_x2)
generation = rgen(n = 500)
x = generation$x
res = EM(x, 2)
display_problem(res,generation,x)
new_generation1 = tr.dat(generation, noise = 2, sys_biais = 1, censor = 0.5)
new_x1 = new_generation1$x
new_res1 = EM(new_x1, 2)
display_problem(new_res1,generation,new_x1)
new_generation2 = tr.dat(generation, noise = 10, sys_biais = 1, censor = 0.5)
new_x2 = new_generation2$x
new_res2 = EM(new_x2, 2)
#display_problem(new_res2,generation,new_x2)
source('D:/Users/emmanuel/OneDrive/M2/boulot/Markov chains and Montecarlo/projet/code.R', encoding = 'UTF-8', echo=TRUE)
source('D:/Users/emmanuel/OneDrive/M2/boulot/Markov chains and Montecarlo/projet/code.R', encoding = 'UTF-8', echo=TRUE)
View(x)
source('D:/Users/emmanuel/OneDrive/M2/boulot/Markov chains and Montecarlo/projet/code.R', encoding = 'UTF-8', echo=TRUE)
source('D:/Users/emmanuel/OneDrive/M2/boulot/Markov chains and Montecarlo/projet/code.R', encoding = 'UTF-8', echo=TRUE)
source('D:/Users/emmanuel/OneDrive/M2/boulot/Markov chains and Montecarlo/projet/code.R', encoding = 'UTF-8', echo=TRUE)
source('D:/Users/emmanuel/OneDrive/M2/boulot/Markov chains and Montecarlo/projet/code.R', encoding = 'UTF-8', echo=TRUE)
source('D:/Users/emmanuel/OneDrive/M2/boulot/Markov chains and Montecarlo/projet/code.R', encoding = 'UTF-8', echo=TRUE)
régression = function(df, type) {
if (type == "linear") {
model = lm(
df$`proportion de logements fibrés au T3 2020` ~
log(df$`Meilleure estimation des locaux à date`) +
df$`Proportion de HLM` +
df$`Équipements touristiques`,
data = df
)
#summary(model)
par(mfrow=c(2,2))
plot(model)
}
if (type == "logistic") {
model <- glm(
df$`Communes avec fibre` ~
log(df$`Meilleure estimation des locaux à date`) +
df$`Proportion de HLM` +
df$`Équipements touristiques`,
data = df,
family = binomial(link = "logit")
)
par(mfrow=c(2,2))
plot(model)
#summary(log.model)
}
return (model)
}
régression = function(df, type) {
if (type == "linear") {
model = lm(
df$`proportion de logements fibrés au T3 2020` ~
log(df$`Meilleure estimation des locaux à date`) +
df$`Proportion de HLM` +
df$`Équipements touristiques`,
data = df
)
#summary(model)
par(mfrow=c(2,2))
plot(model)
}
if (type == "logistic") {
model <- glm(
df$`Communes avec fibre` ~
log(df$`Meilleure estimation des locaux à date`) +
df$`Proportion de HLM` +
df$`Équipements touristiques`,
data = df,
family = binomial(link = "logit")
)
par(mfrow=c(2,2))
plot(model)
#summary(log.model)
}
return (model)
}
regression = régression(df_paca, "logistic")
summary(regression)
source('~/Gitlab/journalisme_donnees/code.R', encoding = 'UTF-8', echo=TRUE)
setwd("~/Gitlab/journalisme_donnees")
source('~/Gitlab/journalisme_donnees/code.R', encoding = 'UTF-8', echo=TRUE)
View(df_paca)
regression = régression(df_guadeloupe, "logistic")
summary(regression)
regression = régression(df_guadeloupe_avec_fibre, "linear")
summary(regression)
View(df_guadeloupe_avec_fibre)
